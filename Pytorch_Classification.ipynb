{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLEEW13uCtiJ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/pytorch/t81_558_class_03_2_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oX6K_-JCtiL"
      },
      "source": [
        "# T81-558: Applications of Deep Neural Networks\n",
        "**Module 3: Introduction to PyTorch**\n",
        "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
        "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzlMdsudCtiL"
      },
      "source": [
        "# Module 3 Material\n",
        "\n",
        "* Part 3.1: Deep Learning and Neural Network Introduction [[Video]](https://www.youtube.com/watch?v=OaJntP14cRA&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_1_neural_net.ipynb)\n",
        "* **Part 3.2: Introduction to PyTorch** [[Video]](https://www.youtube.com/watch?v=z5X2qV5h_p0&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_2_pytorch.ipynb)\n",
        "* Part 3.3: Saving and Loading a PyTorch Neural Network [[Video]](https://www.youtube.com/watch?v=NkG8w_Ua2Yo&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_3_save_load.ipynb)\n",
        "* Part 3.4: Early Stopping in PyTorch to Prevent Overfitting [[Video]](https://www.youtube.com/watch?v=7Fboe7_aTtY&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_4_early_stop.ipynb)\n",
        "* Part 3.5: Extracting Weights and Manual Calculation [[Video]](https://www.youtube.com/watch?v=Fw9VqcqFP_c&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_5_weights.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpVJpj2DCtiM"
      },
      "source": [
        "# Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running and maps Google Drive if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU1AMzx8CtiM",
        "outputId": "014519db-db87-41b6-f5b6-e0a68e2fdffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zg-zNx0CtiN"
      },
      "source": [
        "# Part 3.2: Introduction to PyTorch\n",
        "\n",
        "PyTorch [[Cite:paszke2019pytorch]](https://arxiv.org/abs/1912.01703) is an open-source software library for machine learning in various kinds of perceptual and language understanding tasks. It is currently used for research and production by different teams at [Meta Platforms](https://about.facebook.com/). Companies have built several pieces of deep learning software on top of PyTorch, including Tesla Autopilot, Uber's Pyro, Hugging Face's Transformers, PyTorch Lightning, and Catalyst. PyTorch provides two high-level features: NumPy-like tensor computing and deep neural networks.\n",
        "\n",
        "* [PyTorch Homepage](https://pytorch.org/)\n",
        "* [PyTorch GitHib](https://github.com/pytorch/pytorch)\n",
        "* [PyTorch Forums](https://discuss.pytorch.org/)\n",
        "\n",
        "## Why PyTorch\n",
        "\n",
        "* Supported by Meta\n",
        "* Works well on Windows, Linux, and Mac\n",
        "* Excellent GPU support\n",
        "* Python is an easy to learn programming language\n",
        "* Python is extremely popular in the data science community\n",
        "\n",
        "## Deep Learning Tools\n",
        "PyTorch is not the only game in town. The biggest competitor to PyTorch is TensorFlow/Keras. Listed below are some of the deep learning toolkits actively being supported:\n",
        "\n",
        "* **[TensorFlow](https://www.tensorflow.org/)** - Google's deep learning API.  The focus of this class, along with Keras.\n",
        "* **[Keras](https://keras.io/)** - Acts as a higher-level to Tensorflow.\n",
        "* **[PyTorch](https://pytorch.org/)** - PyTorch is an open-source machine learning library based on the Torch library, used for computer vision and natural language applications processing. Facebook's AI Research lab primarily develops PyTorch.\n",
        "\n",
        "Other deep learning tools:\n",
        "\n",
        "* **[Deeplearning4J](http://deeplearning4j.org/)** - Java-based. Supports all major platforms. GPU support in Java!\n",
        "* **[H2O](http://www.h2o.ai/)** - Java-based.\n",
        "\n",
        "In my opinion, the two primary Python libraries for deep learning are PyTorch and Keras. Generally, PyTorch requires more lines of code to perform the deep learning applications presented in this course. This trait of PyTorch gives Keras an easier learning curve than PyTorch. However, if you are creating entirely new neural network structures in a research setting, PyTorch can make for easier access to some of the low-level internals of deep learning.\n",
        "\n",
        "## Using PyTorch Directly\n",
        "\n",
        "PyTorch is also a low-level mathematics API, similar to [NumPy](http://www.numpy.org/). However, unlike Numpy, PyTorch is built for deep learning. PyTorch compiles these compute graphs into highly efficient C++/[CUDA](https://en.wikipedia.org/wiki/CUDA) code.\n",
        "\n",
        "## PyTorch Linear Algebra Examples\n",
        "\n",
        "PyTorch is a library for linear algebra, other components of PyTorch are a higher-level abstraction for neural networks that you build upon the lower level linear algebra.\n",
        "\n",
        "PyTorch can compute on a GPU, CPU, or other advanced compute device. If you are using a Mac, PyTorch is now adding additional support for Apple silicone (M1, M2, M3, etc). For apple support we will use Metal Performance Shaders (MPS). For this course, we assume you will utilize a GPU (cuda), CPU, or MPS. The following code detects the available device and defines the **device** variable that the following code will use for computation. For parts of this course that I know do not work for MPS, we will fall back to CPU. [CUDA](https://en.wikipedia.org/wiki/CUDA) is an NVIDIA standard for accessing GPU capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "istrQO-2-1DK",
        "outputId": "3de2f86d-f197-4659-8e26-0449d74badf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Make use of a GPU or MPS (Apple) if one is available.\n",
        "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
        "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_dpgVtfCtiS"
      },
      "source": [
        "## Simple TensorFlow Classification: Iris\n",
        "\n",
        "Classification is how a neural network attempts to classify the input into one or more classes.  The simplest way of evaluating a classification network is to track the percentage of training set items classified incorrectly.  We typically score human results in this manner.  For example, you might have taken multiple-choice exams in school in which you had to shade in a bubble for choices A, B, C, or D.  If you chose the wrong letter on a 10-question exam, you would earn a 90%.  In the same way, we can grade computers; however, most classification algorithms do not merely choose A, B, C, or D.  Computers typically report a classification as their percent confidence in each class.  Figure 3.EXAM shows how a computer and a human might respond to question number 1 on an exam.\n",
        "\n",
        "**Figure 3.EXAM: Classification Neural Network Output**\n",
        "![Classification Neural Network Output](images/class-multi-choice.png \"Classification Neural Network Output\")\n",
        "\n",
        "As you can see, the human test taker marked the first question as \"B.\" However, the computer test taker had an 80% (0.8) confidence in \"B\" and was also somewhat sure with 10% (0.1) on \"A.\" The computer then distributed the remaining points to the other two.  In the simplest sense, the machine would get 80% of the score for this question if the correct answer were \"B.\" The computer would get only 5% (0.05) of the points if the correct answer were \"D.\"\n",
        "\n",
        "We previously saw how to train a neural network to predict the MPG of a card. Based on four measurements, we will now see how to predict a class, such as the type of iris flower. The code to classify iris flowers is similar to MPG; however, there are several important differences:\n",
        "\n",
        "* The output neuron count matches the number of classes (in the case of Iris, 3).\n",
        "* The **Softmax** transfer function is utilized by the output layer.\n",
        "* The loss function is **CrossEntropyLoss**.\n",
        "* We call the **train** function to inform PyTorch that we are now in training mode.\n",
        "* Later, we call the **eval** function to inform PyTorch that we are done training and are evaluating the network.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLp65T9JCtiS",
        "outputId": "28975453-2c5f-43fc-eabd-2b8b5f522d47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, loss: 1.1026898622512817\n",
            "Epoch 100, loss: 0.5696811676025391\n",
            "Epoch 200, loss: 0.5677390098571777\n",
            "Epoch 300, loss: 0.5855965614318848\n",
            "Epoch 400, loss: 0.5670421719551086\n",
            "Epoch 500, loss: 0.5657791495323181\n",
            "Epoch 600, loss: 0.5676420331001282\n",
            "Epoch 700, loss: 0.5650959014892578\n",
            "Epoch 800, loss: 0.5637516975402832\n",
            "Epoch 900, loss: 0.5674627423286438\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, out_count)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.softmax(self.fc3(x))\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\",\n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
        "y = le.fit_transform(df['species'])\n",
        "species = le.classes_\n",
        "\n",
        "x = torch.tensor(x,device=device,dtype=torch.float32)\n",
        "y = torch.tensor(y,device=device,dtype=torch.long)\n",
        "\n",
        "model = Net(x.shape[1],len(species)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    loss = criterion(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPM30WdBCtiS",
        "outputId": "185a1859-a5dc-4251-a947-80a4246cc594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ],
      "source": [
        "# Print out number of species found:\n",
        "\n",
        "print(species)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM8-xyDxCtiS"
      },
      "source": [
        "Now that you have a neural network trained, we would like to be able to use it. The following code makes use of our neural network. Exactly like before, we will generate predictions. Notice that three values come back for each of the 150 iris flowers. There were three types of iris (Iris-setosa, Iris-versicolor, and Iris-virginica). We call the **eval** function to inform PyTorch that we are no longer training and wish to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YzlVpw-CtiS",
        "outputId": "2edf87f0-b57a-4f49-b7fc-78ac1c802a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: torch.Size([150, 3])\n",
            "tensor([[9.9997e-01, 2.5089e-05, 7.8737e-38],\n",
            "        [9.9993e-01, 7.3179e-05, 5.8810e-35],\n",
            "        [9.9995e-01, 5.4242e-05, 2.5495e-35],\n",
            "        [9.9989e-01, 1.1081e-04, 1.4094e-33],\n",
            "        [9.9998e-01, 2.4034e-05, 8.7169e-38],\n",
            "        [9.9997e-01, 2.5025e-05, 2.6687e-38],\n",
            "        [9.9994e-01, 6.4238e-05, 1.0197e-34],\n",
            "        [9.9996e-01, 4.1403e-05, 1.5396e-36],\n",
            "        [9.9984e-01, 1.5904e-04, 2.3846e-32],\n",
            "        [9.9993e-01, 6.5191e-05, 2.0829e-35]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "pred = model(x)\n",
        "print(f\"Shape: {pred.shape}\")\n",
        "print(pred[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCay-JrvCtiS"
      },
      "source": [
        "If you would like to turn of scientific notation, the following line can be used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXZne7ZICtiS"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOvMqI7QCtiS"
      },
      "source": [
        "Now we see these values rounded up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PSDexjCtiS",
        "outputId": "df299de1-6686-44cb-a894-9b20639c0d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.99997497 0.00002509 0.        ]\n",
            " [0.9999268  0.00007318 0.        ]\n",
            " [0.99994576 0.00005424 0.        ]\n",
            " [0.99988914 0.00011081 0.        ]\n",
            " [0.9999759  0.00002403 0.        ]\n",
            " [0.99997497 0.00002503 0.        ]\n",
            " [0.99993575 0.00006424 0.        ]\n",
            " [0.99995863 0.0000414  0.        ]\n",
            " [0.999841   0.00015904 0.        ]\n",
            " [0.9999348  0.00006519 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(pred[0:10].cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDC7hxqECtiS"
      },
      "source": [
        "Usually, the program considers the column with the highest prediction to be the prediction of the neural network.  It is easy to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "367mbx_PCtiT",
        "outputId": "c022460c-ec3e-491d-85a8-f9b9f0f73776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2], device='cuda:0')\n",
            "Expected: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predictions: {predict_classes}\")\n",
        "print(f\"Expected: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrcy0Q4xCtiT"
      },
      "source": [
        "Of course, it is straightforward to turn these indexes back into iris species. We use the species list that we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTORTvygCtiT",
        "outputId": "7be0ba26-172c-4b5d-9353-7b6b349cc879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "print(species[predict_classes[1:10].cpu().detach()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljez1ZRACtiT"
      },
      "source": [
        "Accuracy might be a more easily understood error metric.  It is essentially a test score.  For all of the iris predictions, what percent were correct?  The downside is it does not consider how confident the neural network was in each prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zth2S2OcCtiT",
        "outputId": "64510162-96ed-45f7-b72c-8c22e2aa127a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9933333333333333\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "correct = accuracy_score(y.cpu().detach(),predict_classes.cpu().detach())\n",
        "print(f\"Accuracy: {correct}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY07aiLICtiT"
      },
      "source": [
        "The code below performs two ad hoc predictions.  The first prediction is a single iris flower, and the second predicts two iris flowers.  Notice that the **argmax** in the second prediction requires **axis=1**?  Since we have a 2D array now, we must specify which axis to take the **argmax** over.  The value **axis=1** specifies we want the max column index for each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZUSWVGnCtiT",
        "outputId": "e7e4be75-b618-4f1a-b7f3-9cdcafcd9a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3.0684e-10, 2.7745e-01, 7.2255e-01]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "Predict that tensor([[5., 3., 4., 2.]], device='cuda:0') is: Iris-virginica\n"
          ]
        }
      ],
      "source": [
        "sample_flower = torch.tensor( [[5.0,3.0,4.0,2.0]],device=device)\n",
        "pred = model(sample_flower)\n",
        "print(pred)\n",
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predict that {sample_flower} is: {species[predict_classes]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENSZaaRICtiT"
      },
      "source": [
        "You can also predict two sample flowers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdSSkkmwCtiT",
        "outputId": "69bcfb15-5964-46d0-b47a-7d8114d3ee95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3.0684e-10, 2.7745e-01, 7.2255e-01],\n",
            "        [9.9991e-01, 8.7981e-05, 1.5302e-34]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "Predict that these two flowers tensor([[5.0000, 3.0000, 4.0000, 2.0000],\n",
            "        [5.2000, 3.5000, 1.5000, 0.8000]], device='cuda:0') \n",
            "are: ['Iris-virginica' 'Iris-setosa']\n"
          ]
        }
      ],
      "source": [
        "sample_flower = torch.tensor( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]],\n",
        "    device=device)\n",
        "pred = model(sample_flower).to(device)\n",
        "print(pred)\n",
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predict that these two flowers {sample_flower} \")\n",
        "print(f\"are: {species[predict_classes.cpu().detach()]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9 (pytorch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}