{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/pytorch/t81_558_class_03_2_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "ImJE3y-YOy7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **What is Linear Regression?**\n",
        "\n",
        "Linear regression is a supervised learning algorithm that models the relationship between a dependent variable (y) and one or more independent variables (x). The model is a linear equation of the form y = mx + b, where m is the slope of the line and b is the y-intercept.\n",
        "\n",
        "* **Motivation for Linear Regression**\n",
        "\n",
        "Linear regression is a simple and powerful model that can be used to solve a wide variety of problems. For example, it can be used to predict house prices, sales, or customer behavior.\n",
        "\n",
        "* **Designing a Learning Algorithm**\n",
        "\n",
        "The goal of linear regression is to find the values of m and b that minimize the error between the predicted values (y^) and the actual values (y). This can be done using a variety of optimization algorithms, such as gradient descent.\n",
        "\n",
        "* **Linear Regression Algorithm**\n",
        "\n",
        "The linear regression algorithm works by iteratively adjusting the values of m and b to minimize the error between the predicted values and the actual values. The algorithm starts with an initial guess for the values of m and b, and then it iteratively updates the values based on the gradient of the error function.\n",
        "\n",
        "* **Gradient Descent**\n",
        "\n",
        "Gradient descent is an optimization algorithm that can be used to find the minimum of a function. The algorithm works by iteratively moving in the direction of the steepest descent, until it reaches a minimum.\n",
        "\n",
        "* **Batch Gradient Descent**\n",
        "\n",
        "Batch gradient descent is a simple version of gradient descent that uses all of the training data to update the model parameters.\n",
        "\n",
        "* **Stochastic Gradient Descent**\n",
        "\n",
        "Stochastic gradient descent is a more efficient version of gradient descent that uses only a single training example to update the model parameters.\n",
        "\n",
        "* **Evaluating Linear Regression Models**\n",
        "\n",
        "The performance of a linear regression model can be evaluated using a variety of metrics, such as the mean squared error (MSE) or the root mean squared error (RMSE)."
      ],
      "metadata": {
        "id": "bVevOvx8I36y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE and RMSE are both metrics used to evaluate the performance of a regression model. They measure the difference between the predicted values and the actual values, and they are both calculated by squaring the errors.\n",
        "\n",
        "The **mean squared error (MSE)** is the average of the squared errors. It is calculated as follows:\n",
        "\n",
        "```\n",
        "MSE = (1/n) * Σ(y_pred - y)^2\n",
        "```\n",
        "\n",
        "where:\n",
        "\n",
        "* n is the number of data points\n",
        "* y_pred is the predicted value for a data point\n",
        "* y is the actual value for a data point\n",
        "\n",
        "The **root mean squared error (RMSE)** is the square root of the MSE. It is calculated as follows:\n",
        "\n",
        "```\n",
        "RMSE = sqrt(MSE)\n",
        "```\n",
        "\n",
        "The RMSE is often preferred over the MSE because it is in the same units as the dependent variable. This makes it easier to interpret the RMSE and to compare it to other models.\n",
        "\n",
        "For example, if the dependent variable is house prices, then the RMSE would be in dollars. This means that we can say that the model is off by an average of $10,000.\n",
        "\n",
        "The MSE and RMSE are both measures of the accuracy of a regression model. However, the RMSE is more sensitive to outliers than the MSE. This means that if there are a few data points with very large errors, the RMSE will be more affected than the MSE.\n",
        "\n",
        "In general, a lower MSE or RMSE indicates a better fit for the model. However, it is important to consider the units of the MSE or RMSE when interpreting the results.\n",
        "\n",
        "Here is a table that summarizes the differences between MSE and RMSE:\n",
        "\n",
        "| Metric | Formula | Units | Interpretation |\n",
        "|---|---|---|---|\n",
        "| Mean squared error (MSE) | (1/n) * Σ(y_pred - y)^2 | Same as the dependent variable | Average of the squared errors |\n",
        "| Root mean squared error (RMSE) | sqrt(MSE) | Same as the dependent variable | Square root of the average of the squared errors |\n"
      ],
      "metadata": {
        "id": "sCv37jz-KEv0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5AqvyRCID4x",
        "outputId": "48e5df6e-ed0a-490d-e119-922364f3b882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Make use of a GPU or MPS (Apple) if one is available.\n",
        "device = \"mps\" if getattr(torch,'has_mps',False) \\\n",
        "    else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple PyTorch Regression: MPG\n",
        "\n",
        "This example shows how to encode the MPG dataset for regression and predict values. We will see if we can predict the miles per gallon (MPG) for a car based on the car's weight, cylinders, engine size, and other features."
      ],
      "metadata": {
        "id": "PssGUJf3KjER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# You will create a network class for every PyTorch neural network you create.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, in_count, out_count):\n",
        "        super(Net, self).__init__()\n",
        "        # We must define each of the layers.\n",
        "        self.fc1 = nn.Linear(in_count, 50)\n",
        "        self.fc2 = nn.Linear(50, 25)\n",
        "        self.fc3 = nn.Linear(25, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # In the forward pass, we must calculate all of the layers we\n",
        "        # previously defined.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "8afxfTZfI8yO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You define your neural network in the **Net** class above. The class name does not matter; however, it must subclass **nn.Module** and implement both the **__init__** and **forward** methods. The **__init__** method defines the layers of the neural network. In this case, we have a neural network with an input layer equal to the number of inputs you specify from the MPG dataset. The neural network connects these inputs to 50 neurons in the first hidden layer, which are connected to 25 neurons in the second layer. The output neuron count for a layer must always match the input count of the next layer.\n",
        "\n",
        "The **forward** method links these layers together and also defines the transfer functions. For this book, we will generally always use the Relu activation function for hidden layers. The output layer will use no transfer function for a regression neural network like this MPG example. For classification, we use the logistic for binary classification (just two classes) or softmax for two or more classes.\n",
        "\n",
        "For the neural network to perform correctly, everything must align. The **__init__** method must specify all layers with the same number of outputs as inputs for each connection. Finally, the **forward** method must link all the layers together, in the correct order.\n",
        "\n",
        "We will begin by reading the MPG dataset."
      ],
      "metadata": {
        "id": "87C1fmeZKmNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the MPG dataset.\n",
        "df = pd.read_csv(\n",
        "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\",\n",
        "    na_values=['NA', '?'])\n",
        "\n",
        "cars = df['name']\n",
        "\n",
        "# Handle missing value\n",
        "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
        "\n",
        "# Pandas to Numpy\n",
        "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
        "       'acceleration', 'year', 'origin']].values\n",
        "y = df['mpg'].values # regression\n",
        "\n",
        "# Numpy to PyTorch\n",
        "x = torch.tensor(x,device=device,dtype=torch.float32)\n",
        "y = torch.tensor(y,device=device,dtype=torch.float32)"
      ],
      "metadata": {
        "id": "tZSgBiaVKVGK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Pandas to load the CSV file, as previously demonstrated. We will save the names of the cars, though the car names do not help predict the MPG. Horsepower does have missing values, so we substitute the median value for any missing values. Next, we convert Pandas to NumPy, and Numpy to PyTorch. We select only the fields that we wish to use to predict. As previously discussed, we designed the Net class to detect the size of this data and add the appropriate count of input neurons.\n",
        "\n",
        "We are ready to create the neural network, loss function, and optimizer class with the data loaded."
      ],
      "metadata": {
        "id": "r180jRfbKvNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKG0fXXWK4Sq",
        "outputId": "5a7adc07-d5dd-4195-8a6d-77ea35f125a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([398, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network\n",
        "model = Net(x.shape[1],1).to(device)\n",
        "\n",
        "# Define the loss function for regression\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "aPdRLje3KruV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the neural network with one input equal to the number of columns in the x-input data. We specify one output neuron which will predict the MPG. Next, we define MSELoss as the error function, which is a common choice for regression. We will use the Adam optimizer with a learning rate of 0.01 to train the network. Adam is a common choice, and 0.01 is a good start for a learning rate. The learning rate should never be above 1.0. Too large of a learning rate will fail to learn the problem thoroughly, and too low of a learning rate will take a long time to train. We will see more advanced methods for choosing the learning rate, including schedules that change it throughout training.\n",
        "\n",
        "With the objects created, we can now train the neural network."
      ],
      "metadata": {
        "id": "G2P5-nEfK07d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 1000 epochs.\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x).flatten()\n",
        "    loss = loss_fn(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Display status every 100 epochs.\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC_1wt7cKx9z",
        "outputId": "83c51004-a4eb-470f-c4b9-9823d1d09827"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 23346.607421875\n",
            "Epoch 100, loss: 105.33187103271484\n",
            "Epoch 200, loss: 59.72342300415039\n",
            "Epoch 300, loss: 36.49307632446289\n",
            "Epoch 400, loss: 27.242572784423828\n",
            "Epoch 500, loss: 20.207651138305664\n",
            "Epoch 600, loss: 15.593573570251465\n",
            "Epoch 700, loss: 13.378717422485352\n",
            "Epoch 800, loss: 12.471524238586426\n",
            "Epoch 900, loss: 12.004287719726562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now loop over 1,000 epochs and train the neural network; we define an epoch as one complete pass over the training set. We zero the gradients, so training from the previous epoch does not influence the current epoch. We present the entire training set to the model as one large batch. Later we will see more advanced ways to segment the data. We apply the loss function and use backpropagation to calculate the gradients to update the neural network weights."
      ],
      "metadata": {
        "id": "JJJWg_LYLSWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression Prediction\n",
        "\n",
        "Next, we will perform actual predictions. The program assigns these predictions to the **pred** variable. These are all MPG predictions from the neural network. Notice that this is a 2D array? You can always see the dimensions of what PyTorch returns by printing out **pred.shape**. Neural networks can return multiple values, so the result is always an array. Here the neural network only returns one value per prediction (there are 398 cars, so 398 predictions). However, a 2D range is needed because the neural network has the potential of returning more than one value."
      ],
      "metadata": {
        "id": "EIOPEvADMoML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(x)\n",
        "print(f\"Shape: {pred.shape}\")\n",
        "print(pred[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK1sr5QmMpZq",
        "outputId": "d70586bb-214d-4ace-b0b1-bf1c158f0d3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([398, 1])\n",
            "tensor([[16.3173],\n",
            "        [15.6266],\n",
            "        [16.9481],\n",
            "        [17.1265],\n",
            "        [16.4174],\n",
            "        [11.4317],\n",
            "        [11.5971],\n",
            "        [11.5789],\n",
            "        [11.4165],\n",
            "        [14.3042]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(),\n",
        "  y.cpu().detach()))\n",
        "print(f\"Final score (RMSE): {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZg5lsT4Mt8S",
        "outputId": "9f29db31-031a-4edc-e631-2aa7cb31b18f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 3.4179017543792725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(),y))\n",
        "print(f\"Final score (RMSE): {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhy4opTcMwqC",
        "outputId": "a13dc903-ecc4-44d4-bafe-bcae1114497b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final score (RMSE): 3.4179017543792725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are five main assumptions that need to be met for linear regression to be valid:\n",
        "\n",
        "1. **Linearity:** The relationship between the independent and dependent variables must be linear. This means that the residuals (the difference between the predicted values and the actual values) should be randomly scattered around the line of best fit, and not have any discernible pattern.\n",
        "2. **Homoscedasticity:** The variance of the residuals should be constant across all values of the independent variable. This means that the residuals should be equally spread out around the line of best fit, and not be clustered together in any particular area.\n",
        "3. **Normality:** The residuals should be normally distributed. This means that the residuals should be bell-shaped, with most of the values clustered around the mean and fewer values at the extremes.\n",
        "4. **Independence:** The residuals should be independent of each other. This means that the residuals for one data point should not be correlated with the residuals for any other data point.\n",
        "5. **Multicollinearity:** The independent variables should not be highly correlated with each other. This means that the independent variables should not be too similar to each other, as this can cause the model to be unstable.\n",
        "\n",
        "If any of these assumptions are not met, then the results of the linear regression model may be unreliable.\n",
        "\n",
        "Here are some ways to check for these assumptions:\n",
        "\n",
        "* **Linearity:** You can plot the residuals against the predicted values to see if there is any discernible pattern. You can also use a statistical test, such as the Durbin-Watson test, to formally test for linearity.\n",
        "* **Homoscedasticity:** You can plot the residuals against the independent variable to see if the variance of the residuals is constant. You can also use a statistical test, such as the Breusch-Pagan test, to formally test for homoscedasticity.\n",
        "* **Normality:** You can plot the residuals on a histogram to see if they are normally distributed. You can also use a statistical test, such as the Shapiro-Wilk test, to formally test for normality.\n",
        "* **Independence:** You can use a statistical test, such as the Durbin-Watson test, to formally test for independence.\n",
        "* **Multicollinearity:** You can use a statistical measure, such as the variance inflation factor (VIF), to assess the level of multicollinearity in the model.\n",
        "\n",
        "If any of these assumptions are not met, then you may need to transform the data, remove outliers, or use a different regression model."
      ],
      "metadata": {
        "id": "5IFvJGStLzvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPPpuBK9LOFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}